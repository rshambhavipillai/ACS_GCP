# ğŸ“Š GKE Metrics Monitoring - Complete Solution

## Problem: "Why can't I see metrics in GKE workloads?"

**Answer:** You need a GKE cluster deployed with proper monitoring configuration.

---

## âœ… What We've Set Up For You

### 1. **Application Metrics (`/metrics` endpoint)**
```
âœ“ Request counting (total, errors, rate)
âœ“ Response time tracking (average, p95, p99)
âœ“ Memory metrics (heap, RSS, external)
âœ“ CPU metrics
âœ“ Uptime tracking
âœ“ Process information
âœ“ Health check counts
```

### 2. **Kubernetes Manifests**
```
âœ“ deployment.yaml â†’ With health checks + resource limits
âœ“ monitoring.yaml â†’ ServiceMonitor + PrometheusRules
âœ“ service-account.yaml â†’ RBAC configuration
âœ“ configmap.yaml â†’ Configuration management
âœ“ ingress.yaml â†’ External access
```

### 3. **Documentation**
```
âœ“ GKE_MONITORING_SETUP.md â†’ Complete setup guide
âœ“ GKE_METRICS_QUICK_START.md â†’ Quick reference
âœ“ Este arquivo â†’ Architecture overview
```

---

## ğŸƒ Quick Start Steps (5 minutes)

### Step 1: Create GKE Cluster with Monitoring
```powershell
gcloud container clusters create gcp-compare-cluster `
  --zone us-central1-a `
  --num-nodes 3 `
  --enable-cloud-logging `
  --enable-cloud-monitoring `
  --monitoring=SYSTEM,WORKLOAD,POD
```

### Step 2: Build & Push Docker Image
```powershell
gcloud auth configure-docker
docker build -t gcr.io/acs-stuttgart-2026-semester/gcp-compare-app:latest .
docker push gcr.io/acs-stuttgart-2026-semester/gcp-compare-app:latest
```

### Step 3: Deploy to GKE
```powershell
gcloud container clusters get-credentials gcp-compare-cluster --zone us-central1-a
kubectl apply -f gke/deployment.yaml
```

### Step 4: View Metrics
**Wait 2-3 minutes, then:**
1. Go to **Google Cloud Console**
2. **Kubernetes Engine** > **Workloads**
3. Click **gcp-compare-app**
4. Click **Metrics** tab

---

## ğŸ“Š Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  GKE Cluster (Google Cloud)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚  â”‚   Pod 1              â”‚                                    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  â”‚ gcp-compare    â”‚  â”‚  â”‚ Exponential Backoff  â”‚  
â”‚  â”‚  â”‚ app:8080       â”‚  â”‚  â”‚ Retry Policy         â”‚  
â”‚  â”‚  â”‚                â”‚  â”‚  â”‚                      â”‚  
â”‚  â”‚  â”‚ /health        â”‚â”€â”€â”¼â”€â”€â†’ K8s Probes          â”‚  
â”‚  â”‚  â”‚ /metrics       â”‚  â”‚  â”‚ (liveness & ready)   â”‚  
â”‚  â”‚  â”‚ /api/*         â”‚  â”‚  â”‚                      â”‚  
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  
â”‚  â”‚                       â”‚                                    â”‚
â”‚  â”‚  Resource Requests:   â”‚                                    â”‚
â”‚  â”‚  â€¢ CPU: 100m          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  
â”‚  â”‚  â€¢ Memory: 128Mi      â”‚  â”‚ Real-time Metrics   â”‚  
â”‚  â”‚                       â”‚  â”‚ â€¢ CPU Usage         â”‚  
â”‚  â”‚  Resource Limits:     â”‚  â”‚ â€¢ Memory Usage      â”‚  
â”‚  â”‚  â€¢ CPU: 500m          â”‚  â”‚ â€¢ Network I/O       â”‚  
â”‚  â”‚  â€¢ Memory: 512Mi      â”‚  â”‚ â€¢ Restarts          â”‚  
â”‚  â”‚                       â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚  â”‚   Pod 2              â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  
â”‚  â”‚  [gcp-compare]       â”‚  â”‚ Horizontal Pod Autoscaler   â”‚  
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â€¢ Min: 3 replicas           â”‚  
â”‚                            â”‚ â€¢ Max: 10 replicas          â”‚  
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â€¢ Target CPU: 70%           â”‚  
â”‚  â”‚   Pod 3              â”‚  â”‚ â€¢ Target Memory: 80%        â”‚  
â”‚  â”‚  [gcp-compare]       â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Service Mesh (Optional)                                 â”‚ â”‚
â”‚  â”‚ â€¢ Load Balancer: gcp-compare-service (port 80â†’8080)    â”‚ â”‚
â”‚  â”‚ â€¢ Session Affinity: None                               â”‚ â”‚
â”‚  â”‚ â€¢ Pod Disruption Budget: max 1 unavailable             â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â†’ Cloud Monitoring (Automatic)
         â”œâ”€â”€â†’ Cloud Logging (Automatic)
         â””â”€â”€â†’ Prometheus Scraper (Optional)
              â€¢ ServiceMonitor configured
              â€¢ Metrics available @ /metrics
```

---

## ğŸ“ˆ Metrics Collected

### Automatic Metrics (by GKE)
- CPU utilization (%)
- Memory utilization (%)
- Disk I/O
- Network bandwidth
- Pod restart count
- Replica count

### Custom Application Metrics (from `/metrics`)
- Total requests (counter)
- Total errors (counter)
- Average response time (gauge)
- Uptime (gauge)
- Health check count (counter)
- Memory heap usage (bytes)
- Process uptime (seconds)

---

## ğŸ”§ Configuration Files

### `gke/deployment.yaml`
Contains:
- Pod resource requests/limits âœ“
- Liveness probe âœ“
- Readiness probe âœ“
- HorizontalPodAutoscaler âœ“
- PodDisruptionBudget âœ“
- Prometheus scrape annotations âœ“

### `gke/monitoring.yaml`
Contains:
- ServiceMonitor (for Prometheus)
- PodMonitor (for pod-level metrics)
- PrometheusRule (alert rules)
- Service definition

### `app.js`
Added:
- Metrics collection middleware âœ“
- `/metrics` endpoint âœ“
- Request/error/response-time tracking âœ“

---

## ğŸš€ Deployment Steps

```
1. Infrastructure Setup
   â””â”€ Create GKE cluster with monitoring enabled

2. Build & Registry
   â””â”€ Build Docker image
   â””â”€ Push to Google Container Registry

3. Kubernetes Deployment
   â””â”€ Apply deployment.yaml
   â””â”€ Verify pods are running
   â””â”€ Apply monitoring.yaml (optional)

4. Verification
   â””â”€ Check pod status: kubectl get pods
   â””â”€ Check metrics: kubectl top pods
   â””â”€ View in Cloud Console

5. Monitoring Setup (Optional)
   â””â”€ Install Prometheus Operator
   â””â”€ Install Grafana
   â””â”€ Create dashboards
```

---

## ğŸ” Verification Commands

```bash
# Check cluster
kubectl cluster-info

# Check pods
kubectl get pods
kubectl describe pod <pod-name>

# Check metrics availability
kubectl top pods
kubectl top nodes

# Check resource definition
kubectl get pod <pod-name> -o yaml | grep -A5 resources:

# View app logs
kubectl logs <pod-name>

# Port-forward to access app
kubectl port-forward service/gcp-compare-service 8080:80

# Test metrics endpoint
curl http://localhost:8080/metrics

# Install Prometheus (optional)
helm install prometheus prometheus-community/kube-prometheus-stack
```

---

## ğŸ“Š View Metrics In Cloud Console

### Path 1: Kubernetes Workloads
1. Cloud Console â†’ Kubernetes Engine â†’ Workloads
2. Click "gcp-compare-app"
3. View "Metrics" tab
4. See: CPU, Memory, Network, Restarts

### Path 2: Cloud Monitoring Dashboard
1. Monitoring â†’ Dashboards â†’ Create Dashboard
2. Add Charts
3. Select metrics:
   - kubernetes.io/workload/cpu/core_usage_time
   - kubernetes.io/workload/memory/used_bytes
   - kubernetes.io/workload/network/received_bytes_count

### Path 3: Prometheus (Optional)
1. Install: `helm install prometheus prometheus-community/kube-prometheus-stack`
2. Port-forward: `kubectl port-forward -n monitoring svc/prometheus-kube-prometheus-prometheus 9090:9090`
3. Visit: http://localhost:9090
4. Query: `app_requests_total`, `app_response_time_ms`, etc.

---

## âš ï¸ Common Issues & Solutions

| Issue | Solution |
|-------|----------|
| No metrics showing | Wait 2-3 minutes, check if monitoring is enabled on cluster |
| Pod not starting | Check limits: 512Mi memory might be too low |
| Metrics empty after 5 min | Verify `requests`/`limits` are defined in deployment |
| Prometheus not scraping | Verify ServiceMonitor and Pod both have annotations |
| Dashboard shows no data | Check GKE cluster has `--monitoring=SYSTEM,WORKLOAD` |

---

## âœ… Summary

âœ“ Application has metrics endpoint (`/metrics`)
âœ“ Kubernetes manifests configured with resource limits
âœ“ Health checks enabled (liveness + readiness)
âœ“ Auto-scaling configured (HPA)
âœ“ Monitoring setup documented
âœ“ Ready to deploy to GKE cluster
âœ“ Metrics will auto-appear in Cloud Console

**Next steps:**
1. Create GKE cluster with monitoring enabled
2. Push Docker image to Container Registry  
3. Deploy using provided YAML files
4. Metrics visible in ~3-5 minutes

All the configuration is ready to go! ğŸš€
